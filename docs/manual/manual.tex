\documentclass[12pt]{myland}
\usepackage{pgfplots}

%%% Formatting
\def\<#1>{\texttt{#1}}
\setlength{\parskip}{1em} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%FILE%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\title{\texttt{biacpype} User Manual}
\author{\small{Adcock Lab} \\ \small{Center for Cognitive Neuroscience, Duke University}}
\maketitle
\tableofcontents
\newpage

%%%%% section: Overview
\section{Overview}

    \texttt{biacpype} serves as a pipeline for converting raw fMRI data from Brain Imaging \& Analysis Center
    \href{https://www.biac.duke.edu/}{(BIAC)} at Duke University to the new standard Brain Imaging Data Structure
    \href{http://bids.neuroimaging.io/}{(BIDS)} format. The main parts of \texttt{biacpype} contains:

    \begin{itemize}
        \item \texttt{util}: BIAC dataset validation
        \item \texttt{biac2bids}: conversion from BIAC to BIDS
        \item \texttt{helper}: helper scripts
    \end{itemize}

    In a nutshell, \<biacpype> serves as an adapter to the \<bxh2bids> code developed by John Graner from LaBar 
    lab. This is the core of the conversion; all kudos to John!

    The structure of this repository is: \par \vspace{.2in}

    \begin{lstlisting}
|-biacpype // serves as the library
|    |
|    |_biac2bids
|    |_ ...
|
|-scripts  // scripts for running a variety of pipelines
|    |
|    |_convert_to_bids.py
|    |_ ...
|-tutorial // a tutorial notebook
|
|-docs     // documentation 
    |_ ...
    \end{lstlisting}

    To install dependencies of this repo, run
    \begin{lstlisting}[xleftmargin=.25\textwidth, xrightmargin=.25\textwidth, backgroundcolor=\color{lightgray}, framexleftmargin=1em, framexrightmargin=1em]
    pip install -r requirements.txt
    \end{lstlisting}        

    The following section will introduce main modules of \texttt{biacpype}, and the corresponding scripts for using
    the pipelines. 

    If you have any questions, please email Preston at 
    \href{mailto:linxing.jiang@duke.edu}{linxing.jiang@duke.edu}
    or \href{mailto:prestonj@cs.washington.edu}{prestonj@cs.washington.edu}. \par
    
    You can also go to
    \href{https://gitter.im/MotivatedMemoryLab/biacpype}{Gitter Chatroom: https://gitter.im/MotivatedMemoryLab/biacpype} to ask for help!
    You will need to log in with your GitHub account.

\newpage
%%%%% section: util
\section{\texttt{util}}
This is the module which serves as the utility module. It contains validation functionality to let you validate your 
dataset from BIAC to check if it is ready to be converted. 

\subsection{Dataset Structure}
   The pipeline makes the following assumptions on the format of your raw data from BIAC:
   \begin{lstlisting}[escapeinside={(*@}{@*)}]
|-Data
|    |
|    |-Func
|    |  |
|    |  |-<[date_]subject>
|    |  |       |
|    |  |       |-<biac5_subject_task_run>.bxh
|    |  |       |-<biac5_subject_task_run>.nii.gz
|    |  |       |-...
|    |  |       |-(*@\color{red}{series\_order\_note.tsv}@*)
|    |  |-...
|    |
|    |-Anat
|       |-<[date_]subject>
|       |       |
|       |       |-<biac5_subject_task_run>.bxh
|       |       |-<biac5_subject_task_run>.nii.gz
|       |       |-...
|       |       |-(*@\color{red}{series\_order\_note.tsv}@*)
|       |-...
|
|-(*@\color{red}{biac\_id\_mapping.tsv}@*)
    \end{lstlisting}

    Explanations:
    \begin{itemize}
        \item \<Data> folder has to contain \<Func> and \<Anat>, and they must have the exact same folders
        \item Subfolders in \<Func> and \<Anat> are in format \<[date\_]subject> where \<[date\_]> is optional. E.g.
            \<19354> and \<20140101\_19354> are both acceptable.
        \item Each file in \<Func> and \<Anat> must in format \<biac5\_subject\_task\_run>. Usually, \<task> is a single
        digit number, \<run> is two-digit. E.g. \<biac5\_19354\_4\_01.bxh>
        \item Each subfolder in \<Func> and \<Anat> \textbf{must contain} a \color{red}{\<series\_order\_note.tsv>} \color{black} to tell the pipeline
        what each \<task> number stands for. E.g. 4 stands for ``TRAIN''. Requirements for this file are later explained.
        \item In the same folder containing \<Data>, there \textbf{must contain} a \color{red}{\<biac\_id\_mapping.tsv>}
        \color{black} which tells the pipeline the mapping from BIAC\_ID (e.g. 19354) to the session name (e.g. Session-1) and the
        Real\_ID used by your lab (e.g. 101). Requirements for this file are later explained.
    \end{itemize}

    Requirements on \<series\_order\_note.tsv> are as follows:
    \begin{table}[!htb]
        \centering
        \begin{tabularx}{.6\linewidth}{Y|Y}
             4 & LOCALIZER \\
             7 & TRAIN1 \\
             ... & ... \\
        \end{tabularx}
    \end{table}
    \par
    Note:
    \begin{itemize}
        \item The values must be \textbf{tab} separated.
        \item The first column serves as the primary key (they must be unique).
        \item The first column must be task code, and the second column must be the task name. There can only be two columns.
        \item If you have fmap data task code, be sure to name the translation \textbf{``fmap''} exactly. In this way, the data
            will be put in \<fmap> folder after BIDS conversion, not \<anat> folder.
    \end{itemize}

    Requirements on \<biac\_id\_mapping.tsv> are as follows:
    \begin{table}[!htb]
        \centering
        \begin{tabularx}{.6\linewidth}{Y|Y|Y}
            BIAC\_ID & [Session] & Real\_ID \\ \hline
             19354 & SRM & 101 \\
             19338 & SPM & 102 \\
             19368 & SPM & 101 \\
             ... & ... & ... \\
         \end{tabularx}
    \end{table}
    \par
    Note:
    \begin{itemize}
        \item The values must be \textbf{tab} separated.
        \item The first column serves as the primary key (they must be unique)
        \item The headers must follow the rules (watch letter cases)!
        \item If your experiment does not have multiple sessions, you can ignore the \<Session> column
    \end{itemize}

    %%%%% script
    \subsection{Scripts}
    The script associated with this module is \<scripts/validate\_biac\_study\_folder.py>. You need one 
    command line input, \<STUDY\_PATH>. \par

    Run
    \begin{lstlisting}[xleftmargin=.15\textwidth, xrightmargin=.15\textwidth, backgroundcolor=\color{lightgray}, framexleftmargin=1em, framexrightmargin=1em]
    python scripts/validate_biac_study_folder.py -h
    \end{lstlisting}        
    to see help messages.  \par

    Run
    \begin{lstlisting}[xleftmargin=.1\textwidth, xrightmargin=.1\textwidth, backgroundcolor=\color{lightgray}, framexleftmargin=1em, framexrightmargin=1em]
    python scripts/validate_biac_study_folder.py STUDY_PATH
    \end{lstlisting}        
    to validate your dataset. \par

    If there are errors, they will be printed out to console like this:
        \begin{lstlisting}[xleftmargin=.2\textwidth, xrightmargin=.2\textwidth]

        ### Following erros happend: ###
        ... 


        \end{lstlisting}        
   
    All the error logs are saved in \<biacpype/logs/validation.log>. If there are no errors,
    you should see the following printed out:
    \begin{center}\<Your study path passed validation! You are now ready for conversion>\end{center}



%%%%% section: biac2bids
\section{\texttt{biac2bids}}

   \texttt{biac2bids} module is the pipeline for converting raw data from BIAC in forms of \texttt{bxh} and
   \texttt{nifti} to BIDS format. It wraps the \<bxh2bids> code developed by John with validation,
   automatic Json file generation, and naming clean-up. The workflow is as follows:

    \begin{figure}[h]
        \begin{mybox}
            \centering
        \begin{tikzpicture}[>=latex,shape aspect=1,scale=0.7]
        \tikzstyle{box} = [rectangle, draw, minimum height=1cm, minimum width=2cm]
        % Disk Interface %
        \node[box, dashed] (biac) at (-6, 0) {Data from biac};
        \node[box, dashed] (json) at (0, 0) {\texttt{json} files};
        \path[->] (biac) edge node[midway, above] {\tiny{\texttt{generate\_json}}} (json);
        \node[box, dashed] (bxh) at (6, 0) {raw BIDS files};
        \path[->] (json) edge node[midway, above] {\tiny{\texttt{bxh2bids}}} (bxh);
        \node[box, dashed] (done) at (12, 0) {valid BIDS files};
        \path[->] (bxh) edge node[midway, above] {\tiny{\texttt{clean\_names}}} (done);
        \end{tikzpicture}
        \end{mybox}
        \caption{\<biac2bids> workflow}
    \end{figure}

    %%%%% subsection: Scripts
    \subsection{Scripts}
    The script associated with this module is \<scripts/convert\_to\_bids.py>. There are four 
    parameters the user has to give to command line. They are:
    \begin{itemize}
        \item \<STUDY\_PATH>: the path to your study file (which contains \<Data> and \<bids\_id\_mapping.csv>)
        \item \<JSON\_OUTPUT\_PATH>: the path where the user wants the json files to be saved
        \item \<BIDS\_PATH>: the path where the user wants the new BIDS format data to be saved
        \item \<LOG\_PATH>: the path where the user wants the logs to be saved
    \end{itemize}

    Run
    \begin{lstlisting}[xleftmargin=.22\textwidth, xrightmargin=.22\textwidth, backgroundcolor=\color{lightgray}]
    python scripts/convert_to_bids.py -h
    \end{lstlisting}        
    to see help messages. \par

    Run
    \begin{lstlisting}[backgroundcolor=\color{lightgray}]
    python scripts/convert_to_bids.py STUDY_PATH JSON_PATH BIDS_PATH LOG_PATH
    \end{lstlisting}        
    to convert your dataset. \par

    %%%%% common errors
    \subsection{Common Errors During Conversion}
    \begin{enumerate}[itemsep=5pt]
        \item \<Log file already exists!?  They should be time-stamped down to the minute!> \par
            This is because you run the conversion too frequently! \par
            \color{red}Quick solution: \color{black}delete all your logs and run it again.

        \item \<Error:root:scan description not found in template file!> \par
            This is because the scan description (printed out next line) is not saved in template file. \par
            \color{red}Quick solution: \color{black}add the description to the scan description file following
            its format. \par
            For an example, please refer to the tutorial notebook and the slides!

        \item \<Output file already exists: ...> \par
            This is because some bids files already exist at the BIDS path! (often because the conversion stopped in
            the middle) \par
            \color{red}Quick solution: \color{black}delete the existing bids files.
    \end{enumerate}


\section{\<helper>}
The \<helper> module aims to provide some helper scripts to make the conversion process simply. If you have features which 
you think would be useful and the module does not cover, please let us know through GitHub
\href{https://github.com/MotivatedMemoryLab/biacpype/issues}{Feature Requests}, or better, build them in your forked
branch and submit \href{https://github.com/MotivatedMemoryLab/biacpype/pulls}{Pull Requests}!

\subsection{\<create\_series\_order\_notes.py>}
If you are converting an old dataset, you may not have \<series\_order\_note.tsv> ready. This script can help you with
that. You will need edit the script and tweak a few things:

\begin{lstlisting}[escapeinside={(*@}{@*)}]
STUDY_PATH = "/Volumes/lj146/Documents/CBT.01/" (*@\tikzmark{d}@*)
# translation dictionary
anat_d = {
    "001": "fmap", 
    "003": "Anat", (*@\tikzmark{a}@*)
    "005": "Anat",
}

func_d = {
    "4": "LOCALIZER", 
    "5": "TRAIN",
    "6": "REST", (*@\tikzmark{b}@*) 
    "7": "FINISH" 
}
subjs = ["20150220_19480"] # or None for all subjects   (*@\tikzmark{c}@*)  

### creation begins ###
set_paths(STUDY_PATH=STUDY_PATH)
populate_file("Anat", anat_d, subjs=subjs)
populate_file("Func", func_d, subjs=subjs)
\end{lstlisting}

\begin{tikzpicture}[remember picture,overlay]
    \node[red] (anat) at ($(pic cs:a) + (5, 0)$) {\<series\_order\_note.tsv> for \<Anat>};
    \draw[red, rounded corners] ($(pic cs:a) + (-4.2, 1.2)$) rectangle ($(pic cs:a) + (0, -0.84)$);
    \path[->, red] (anat) edge (pic cs:a);

    \node[red] (func) at ($(pic cs:b) + (6, 0)$) {\<series\_order\_note.tsv> for \<Func>};
    \draw[red, rounded corners] ($(pic cs:b) + (-3.8, 1.5)$) rectangle ($(pic cs:b) + (1, -0.85)$);
    \path[->, red] (func) edge ($(pic cs:b) + (1, 0)$);

    \node[red] (subj) at ($(pic cs:c) + (3, 0)$) {add to which subject};
    \draw[red, rounded corners] ($(pic cs:c) + (-12.2, 0.4)$) rectangle ($(pic cs:c) + (0, -0.4)$);
    \path[->, red] (subj) edge (pic cs:c);

    \node[red] (study) at ($(pic cs:d) + (3, 0)$) {Your study path};
    \draw[red, rounded corners] ($(pic cs:d) + (-10.45, 0.4)$) rectangle ($(pic cs:d) + (0, -0.2)$);
    \path[->, red] (study) edge (pic cs:d);
\end{tikzpicture}

The four red rectangles are the areas you need to change to create the files. They should be 
straightforward to understand. Note that to add the files to \textbf{all} subjects, set
\[\text{\<subjs = None>}\]

After you change the fields, run
    \begin{lstlisting}[xleftmargin=.2\textwidth, xrightmargin=.2\textwidth, backgroundcolor=\color{lightgray}]
    python scripts/create_series_order_notes.py
    \end{lstlisting}        
to create the files. \par

Sometimes, not all of your subjects have the exactly same task code mapping. You will need to manually
change these after the tsv files are populated to all folders.


\section{Contributing and Asking for Help!}
We hope you can contribute and help us develop this pipeline better through:
\begin{itemize}
    \item Create GitHub Issues and Pull Requests to let us be aware of the uncaught bugs
    \item Chat on Gitter and ask for help
    \item Let us know what feature you wish the pipeline had 
\end{itemize}
\end{document}
